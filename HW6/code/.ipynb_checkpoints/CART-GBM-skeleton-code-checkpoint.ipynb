{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:22:56.109109Z",
     "start_time": "2020-04-29T12:22:56.097595Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "import graphviz\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:22:57.910997Z",
     "start_time": "2020-04-29T12:22:57.897296Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = np.loadtxt('svm-train.txt')\n",
    "data_test = np.loadtxt('svm-test.txt')\n",
    "x_train, y_train = data_train[:, 0: 2], data_train[:, 2].reshape(-1, 1)\n",
    "x_test, y_test = data_test[:, 0: 2], data_test[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:32:46.756018Z",
     "start_time": "2020-04-29T18:32:46.752914Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change target to 0-1 label\n",
    "y_train_label = np.array(list(map(lambda x: 1 if x > 0 else 0, y_train))).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:52:26.553416Z",
     "start_time": "2020-04-29T18:52:26.538233Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decision_Tree(BaseEstimator):\n",
    "     \n",
    "    def __init__(self, split_loss_function, leaf_value_estimator,\n",
    "                 depth=0, min_sample=5, max_depth=10):\n",
    "        '''\n",
    "        Initialize the decision tree classifier\n",
    "\n",
    "        :param split_loss_function: method for splitting node\n",
    "        :param leaf_value_estimator: method for estimating leaf value\n",
    "        :param depth: depth indicator, default value is 0, representing root node\n",
    "        :param min_sample: an internal node can be splitted only if it contains points more than min_smaple\n",
    "        :param max_depth: restriction of tree depth.\n",
    "        '''\n",
    "        self.split_loss_function = split_loss_function\n",
    "        self.leaf_value_estimator = leaf_value_estimator\n",
    "        self.depth = depth\n",
    "        self.min_sample = min_sample\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        This should fit the tree classifier by setting the values self.is_leaf, \n",
    "        self.split_id (the index of the feature we want ot split on, if we're splitting),\n",
    "        self.split_value (the corresponding value of that feature where the split is),\n",
    "        and self.value, which is the prediction value if the tree is a leaf node.  If we are \n",
    "        splitting the node, we should also init self.left and self.right to be Decision_Tree\n",
    "        objects corresponding to the left and right subtrees. These subtrees should be fit on\n",
    "        the data that fall to the left and right,respectively, of self.split_value.\n",
    "        This is a recurisive tree building procedure. \n",
    "        \n",
    "        :param X: a numpy array of training data, shape = (n, m)\n",
    "        :param y: a numpy array of labels, shape = (n, 1)\n",
    "\n",
    "        :return self\n",
    "        '''\n",
    "        # Your code goes here\n",
    "        # remember to set self.is_leaf, self.split_id,  self.split_value,\n",
    "        # self.value, self.left, self.right\n",
    "        \n",
    "        # initialize\n",
    "        n, d = X.shape[0], X.shape[1]\n",
    "        min_loss = self.split_loss_function(y) # initialize a minimal loss, we will update it later\n",
    "        best_flag = None # for marking the best splitting point (flag)\n",
    "        best_index_order = None # for marking the order of the X, y matrix with the best loss\n",
    "    \n",
    "        ### step 1: check pruning:  self.min_sample; self.max_depth ###\n",
    "        # 1. threshold for pruning, this is the leaf\n",
    "        if n <= self.min_sample or self.depth == self.max_depth:\n",
    "            self.is_leaf = True\n",
    "            self.value = self.leaf_value_estimator(y)\n",
    "            return self\n",
    "        \n",
    "        ### step 2: if not a leaf, keep splitting the parent nodes of the subtree ###\n",
    "        #self.is_leaf = False\n",
    "        # brute-force on each feature, d\n",
    "        for dim in range(d):\n",
    "            # sort X by dim\n",
    "            index_order = np.argsort(X[:, dim]) # get the ordered index\n",
    "            X_sorted, y_sorted = X[index_order], y[index_order]\n",
    "            # find the splitting flag among sorted data points\n",
    "            # there are n-1 gaps in n data points\n",
    "            for flag in range(n-1):\n",
    "                # current loss\n",
    "                curr_loss = ((flag+1)*self.split_loss_function(y_sorted[:flag+1]) + (n-flag-1)*self.split_loss_function(y_sorted[flag+1:])) / len(y_sorted)\n",
    "                if curr_loss < min_loss:\n",
    "                    # update min_loss\n",
    "                    min_loss = curr_loss\n",
    "                    self.split_id = flag\n",
    "                    self.split_value = (X_sorted[flag, dim] + X_sorted[flag+1, dim])/2\n",
    "                    # mark the best flag for further discuss\n",
    "                    best_flag = flag\n",
    "                    best_index_order = index_order\n",
    "\n",
    "        ### step 3: use RECURSION to build the left and right subtrees ###\n",
    "        # after finding the best flag for this feature, we continue the subtree\n",
    "        if best_flag != None: # be careful for best_flag == 0\n",
    "            # initialize\n",
    "            # left subtree\n",
    "            self.left = Decision_Tree(self.split_loss_function,\n",
    "                                      self.leaf_value_estimator,\n",
    "                                      self.depth+1,\n",
    "                                      self.min_sample,\n",
    "                                      self.max_depth)\n",
    "            # right subtree\n",
    "            self.right = Decision_Tree(self.split_loss_function,\n",
    "                                      self.leaf_value_estimator,\n",
    "                                      self.depth+1,\n",
    "                                      self.min_sample,\n",
    "                                      self.max_depth)\n",
    "            # fit\n",
    "            X_best_sorted = X[best_index_order]\n",
    "            y_best_sorted = y[best_index_order]\n",
    "            # fit left subtree\n",
    "            self.left.fit(X_best_sorted[:best_flag+1], y_best_sorted[:best_flag+1])\n",
    "            # fit right subtree\n",
    "            self.right.fit(X_best_sorted[best_flag+1:], y_best_sorted[best_flag+1:])\n",
    "        else:\n",
    "            self.is_leaf = True\n",
    "            self.value = self.leaf_value_estimator(y)\n",
    "        return self\n",
    "\n",
    "    def predict_instance(self, instance):\n",
    "        '''\n",
    "        Predict label by decision tree\n",
    "\n",
    "        :param instance: a numpy array with new data, shape (1, m)\n",
    "\n",
    "        :return whatever is returned by leaf_value_estimator for leaf containing instance\n",
    "        '''\n",
    "        if self.is_leaf:\n",
    "            return self.value\n",
    "        if instance[self.split_id] <= self.split_value:\n",
    "            return self.left.predict_instance(instance)\n",
    "        else:\n",
    "            return self.right.predict_instance(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:45:58.844030Z",
     "start_time": "2020-04-29T18:45:58.841749Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$entropy = -\\sum_{i=1}^c P(A_i) \\cdot \\log_2 P(A_i)$$\n",
    "\n",
    "$$gini = 1 - \\sum_{i=1}^c P(A_i)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:45:59.422103Z",
     "start_time": "2020-04-29T18:45:59.414474Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_entropy(label_array):\n",
    "    '''\n",
    "    Calulate the entropy of given label list\n",
    "    \n",
    "    :param label_array: a numpy array of labels shape = (n, 1)\n",
    "    :return entropy: entropy value\n",
    "    '''\n",
    "    # Your code goes here\n",
    "    num_samples = label_array.shape[0]\n",
    "    label_array_1D = label_array.reshape(num_samples) # 2D->1D\n",
    "    cls_count_dict = Counter(label_array_1D) # dictionary: key=class; value=count\n",
    "    counts = np.array([cts for cts in cls_count_dict.values()]) # counts for each class\n",
    "    prob = counts/num_samples # an array of probability\n",
    "    entropy = -prob.dot(np.log2(prob))\n",
    "    return entropy\n",
    "\n",
    "def compute_gini(label_array):\n",
    "    '''\n",
    "    Calulate the gini index of label list\n",
    "    \n",
    "    :param label_array: a numpy array of labels shape = (n, 1)\n",
    "    :return gini: gini index value\n",
    "    '''\n",
    "    # Your code goes here\n",
    "    num_samples = label_array.shape[0]\n",
    "    label_array_1D = label_array.reshape(num_samples) # 2D->1D\n",
    "    cls_count_dict = Counter(label_array_1D) # dictionary: key=class; value=count\n",
    "    counts = np.array([cts for cts in cls_count_dict.values()]) # counts for each class\n",
    "    prob = counts/num_samples # an array of probability\n",
    "    gini = 1-np.sum(np.square(prob))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:45:59.497655Z",
     "start_time": "2020-04-29T18:45:59.494263Z"
    }
   },
   "outputs": [],
   "source": [
    "def most_common_label(y):\n",
    "    '''\n",
    "    Find most common label\n",
    "    '''\n",
    "    label_cnt = Counter(y.reshape(len(y)))\n",
    "    label = label_cnt.most_common(1)[0][0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:45:59.654748Z",
     "start_time": "2020-04-29T18:45:59.650339Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classification_Tree(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    loss_function_dict = {\n",
    "        'entropy': compute_entropy,\n",
    "        'gini': compute_gini\n",
    "    }\n",
    "\n",
    "    def __init__(self, loss_function='entropy', min_sample=5, max_depth=10):\n",
    "        '''\n",
    "        :param loss_function(str): loss function for splitting internal node\n",
    "        '''\n",
    "\n",
    "        self.tree = Decision_Tree(self.loss_function_dict[loss_function],\n",
    "                                most_common_label,\n",
    "                                0, min_sample, max_depth)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.tree.fit(X,y)\n",
    "        return self\n",
    "\n",
    "    def predict_instance(self, instance):\n",
    "        value = self.tree.predict_instance(instance)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:52:30.206956Z",
     "start_time": "2020-04-29T18:52:29.550777Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Decision_Tree' object has no attribute 'is_leaf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-6c6f93032898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mclf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         ['Depth = {}'.format(n) for n in range(1, 7)]):\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-6c6f93032898>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mclf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         ['Depth = {}'.format(n) for n in range(1, 7)]):\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-e68560de8219>\u001b[0m in \u001b[0;36mpredict_instance\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-548a93797242>\u001b[0m in \u001b[0;36mpredict_instance\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m \u001b[0mwhatever\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mby\u001b[0m \u001b[0mleaf_value_estimator\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         '''\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Decision_Tree' object has no attribute 'is_leaf'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training classifiers with different depth\n",
    "clf1 = Classification_Tree(max_depth=1)\n",
    "clf1.fit(x_train, y_train_label)\n",
    "\n",
    "clf2 = Classification_Tree(max_depth=2)\n",
    "clf2.fit(x_train, y_train_label)\n",
    "\n",
    "clf3 = Classification_Tree(max_depth=3)\n",
    "clf3.fit(x_train, y_train_label)\n",
    "\n",
    "clf4 = Classification_Tree(max_depth=4)\n",
    "clf4.fit(x_train, y_train_label)\n",
    "\n",
    "clf5 = Classification_Tree(max_depth=5)\n",
    "clf5.fit(x_train, y_train_label)\n",
    "\n",
    "clf6 = Classification_Tree(max_depth=6)\n",
    "clf6.fit(x_train, y_train_label)\n",
    "\n",
    "\n",
    "# Plotting decision regions\n",
    "x_min, x_max = x_train[:, 0].min() - 1, x_train[:, 0].max() + 1\n",
    "y_min, y_max = x_train[:, 1].min() - 1, x_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(2, 3, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1, 2]),\n",
    "                        [clf1, clf2, clf3, clf4, clf5, clf6],\n",
    "                        ['Depth = {}'.format(n) for n in range(1, 7)]):\n",
    "    Z = np.array([clf.predict_instance(x) for x in np.c_[xx.ravel(), yy.ravel()]])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0], idx[1]].scatter(x_train[:, 0], x_train[:, 1], c=y_train_label.reshape(-1), alpha=0.8) #c\n",
    "    axarr[idx[0], idx[1]].set_title(tt)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare decision tree with tree model in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=5)\n",
    "clf.fit(x_train, y_train_label)\n",
    "export_graphviz(clf, out_file='tree_classifier.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize decision tree\n",
    "!dot -Tpng tree_classifier.dot -o tree_classifier.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(filename='tree_classifier.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression Tree Specific Code\n",
    "def mean_absolute_deviation_around_median(y):\n",
    "    '''\n",
    "    Calulate the mean absolute deviation around the median of a given target list\n",
    "    \n",
    "    :param y: a numpy array of targets shape = (n, 1)\n",
    "    :return mae\n",
    "    '''\n",
    "    # Your code goes here\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Regression_Tree():\n",
    "    '''\n",
    "    :attribute loss_function_dict: dictionary containing the loss functions used for splitting\n",
    "    :attribute estimator_dict: dictionary containing the estimation functions used in leaf nodes\n",
    "    '''\n",
    "\n",
    "    loss_function_dict = {\n",
    "        'mse': np.var,\n",
    "        'mae': mean_absolute_deviation_around_median\n",
    "    }\n",
    "\n",
    "    estimator_dict = {\n",
    "        'mean': np.mean,\n",
    "        'median': np.median\n",
    "    }\n",
    "    \n",
    "    def __init__(self, loss_function='mse', estimator='mean', min_sample=5, max_depth=10):\n",
    "        '''\n",
    "        Initialize Regression_Tree\n",
    "        :param loss_function(str): loss function used for splitting internal nodes\n",
    "        :param estimator(str): value estimator of internal node\n",
    "        '''\n",
    "\n",
    "        self.tree = Decision_Tree(self.loss_function_dict[loss_function],\n",
    "                                  self.estimator_dict[estimator],\n",
    "                                  0, min_sample, max_depth)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.tree.fit(X,y)\n",
    "        return self\n",
    "\n",
    "    def predict_instance(self, instance):\n",
    "        value = self.tree.predict_instance(instance)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit regression tree to one-dimensional regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_krr_train = np.loadtxt('krr-train.txt')\n",
    "data_krr_test = np.loadtxt('krr-test.txt')\n",
    "x_krr_train, y_krr_train = data_krr_train[:,0].reshape(-1,1),data_krr_train[:,1].reshape(-1,1)\n",
    "x_krr_test, y_krr_test = data_krr_test[:,0].reshape(-1,1),data_krr_test[:,1].reshape(-1,1)\n",
    "\n",
    "# Training regression trees with different depth\n",
    "clf1 = Regression_Tree(max_depth=1,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf1.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf2 = Regression_Tree(max_depth=2,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf2.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf3 = Regression_Tree(max_depth=3,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf3.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf4 = Regression_Tree(max_depth=4,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf4.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf5 = Regression_Tree(max_depth=5,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf5.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf6 = Regression_Tree(max_depth=6,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf6.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "plot_size = 0.001\n",
    "x_range = np.arange(0., 1., plot_size).reshape(-1, 1)\n",
    "\n",
    "f2, axarr2 = plt.subplots(2, 3, sharex='col', sharey='row', figsize=(15, 10))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1, 2]),\n",
    "                        [clf1, clf2, clf3, clf4, clf5, clf6],\n",
    "                        ['Depth = {}'.format(n) for n in range(1, 7)]):\n",
    "\n",
    "    y_range_predict = np.array([clf.predict_instance(x) for x in x_range]).reshape(-1, 1)\n",
    "  \n",
    "    axarr2[idx[0], idx[1]].plot(x_range, y_range_predict, color='r')\n",
    "    axarr2[idx[0], idx[1]].scatter(x_krr_train, y_krr_train, alpha=0.8)\n",
    "    axarr2[idx[0], idx[1]].set_title(tt)\n",
    "    axarr2[idx[0], idx[1]].set_xlim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pseudo-residual function.\n",
    "#Here you can assume that we are using L2 loss\n",
    "\n",
    "def pseudo_residual_L2(train_target, train_predict):\n",
    "    '''\n",
    "    Compute the pseudo-residual based on current predicted value. \n",
    "    '''\n",
    "    return train_target - train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gradient_boosting():\n",
    "    '''\n",
    "    Gradient Boosting regressor class\n",
    "    :method fit: fitting model\n",
    "    '''\n",
    "    def __init__(self, n_estimator, pseudo_residual_func, learning_rate=0.1, min_sample=5, max_depth=3):\n",
    "        '''\n",
    "        Initialize gradient boosting class\n",
    "        \n",
    "        :param n_estimator: number of estimators (i.e. number of rounds of gradient boosting)\n",
    "        :pseudo_residual_func: function used for computing pseudo-residual\n",
    "        :param learning_rate: step size of gradient descent\n",
    "        '''\n",
    "        self.n_estimator = n_estimator\n",
    "        self.pseudo_residual_func = pseudo_residual_func\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_sample = min_sample\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, train_data, train_target):\n",
    "        '''\n",
    "        Fit gradient boosting model\n",
    "        '''\n",
    "        # Your code goes here \n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        '''\n",
    "        Predict value\n",
    "        '''\n",
    "        # Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-D GBM visualization - SVM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting decision regions\n",
    "x_min, x_max = x_train[:, 0].min() - 1, x_train[:, 0].max() + 1\n",
    "y_min, y_max = x_train[:, 1].min() - 1, x_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(2, 3, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "for idx, i, tt in zip(product([0, 1], [0, 1, 2]),\n",
    "                       [1, 5, 10, 20, 50, 100], \n",
    "                       ['n_estimator = {}'.format(n) for n in [1, 5, 10, 20, 50, 100]]):\n",
    "    \n",
    "    gbt = gradient_boosting(n_estimator=i, pseudo_residual_func=pseudo_residual_L2, max_depth=2)  \n",
    "    gbt.fit(x_train, y_train)\n",
    "                   \n",
    "    Z = np.sign(gbt.predict(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0], idx[1]].scatter(x_train[:, 0], x_train[:, 1], c=y_train_label, alpha=0.8)\n",
    "    axarr[idx[0], idx[1]].set_title(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D GBM visualization - KRR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_size = 0.001\n",
    "x_range = np.arange(0., 1., plot_size).reshape(-1, 1)\n",
    "\n",
    "f2, axarr2 = plt.subplots(2, 3, sharex='col', sharey='row', figsize=(15, 10))\n",
    "\n",
    "for idx, i, tt in zip(product([0, 1], [0, 1, 2]),\n",
    "                       [1, 5, 10, 20, 50, 100], \n",
    "                       ['n_estimator = {}'.format(n) for n in [1, 5, 10, 20, 50, 100]]):\n",
    "    \n",
    "    gbm_1d = gradient_boosting(n_estimator=i, pseudo_residual_func=pseudo_residual_L2, max_depth=2)  \n",
    "    gbm_1d.fit(x_krr_train, y_krr_train)\n",
    "    \n",
    "    y_range_predict = gbm_1d.predict(x_range)\n",
    "\n",
    "    axarr2[idx[0], idx[1]].plot(x_range, y_range_predict, color='r')\n",
    "    axarr2[idx[0], idx[1]].scatter(x_krr_train, y_krr_train, alpha=0.8)\n",
    "    axarr2[idx[0], idx[1]].set_title(tt)\n",
    "    axarr2[idx[0], idx[1]].set_xlim(0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
